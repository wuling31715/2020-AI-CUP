{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_gpu(N):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(gpus)\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_visible_devices(gpus[N], 'GPU')\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n",
      "3 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "select_gpu(2)\n",
    "epochs = 512\n",
    "batch_size = 1024\n",
    "model_name = 'chinese_roberta_wwm_large_ext_L-24_H-1024_A-16'\n",
    "embedding_path = '/home/Danny/pretrain_model/{}'.format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不用儲存article_id, 轉成list\n",
    "def training_txt_to_list(path):\n",
    "    with open(path, 'r') as f:\n",
    "        txt = str(f.read())\n",
    "    txt_list = txt.split('\\n')\n",
    "    text_label_list = list()\n",
    "    tmp = list()\n",
    "    for line in txt_list:\n",
    "        if line == '--------------------':\n",
    "            text_label_list.append(tmp)\n",
    "            tmp = list()\n",
    "            continue\n",
    "        if line == '':\n",
    "            continue\n",
    "        tmp.append(line)\n",
    "    x = list()\n",
    "    y = list()\n",
    "    for text_label in text_label_list:\n",
    "        text = text_label[0]\n",
    "        label = text_label[2:]\n",
    "        label_list = ['O' for i in range(len(text))]\n",
    "        for i in label:\n",
    "            entity = i.split('\\t')\n",
    "            if int(entity[1]) > int(entity[2]):\n",
    "                continue\n",
    "            b = int(entity[1])\n",
    "            label_list[b] = 'B-{}'.format(entity[-1])\n",
    "            for j in range(int(entity[1])+1, int(entity[2])):\n",
    "                label_list[j] = 'I-{}'.format(entity[-1])\n",
    "        for i, j in enumerate(text):\n",
    "            if j == '，' or j == '。' or j == '？':\n",
    "                label_list[i] = j\n",
    "                \n",
    "        text_list = re.split('\\uff0c|\\u3002|\\uff1f', text)\n",
    "        for sentence in text_list:\n",
    "            x.append([i for i in sentence])\n",
    "        x = x[:-1]\n",
    "            \n",
    "        sentence = list()\n",
    "        for i in label_list:\n",
    "            if i == '，' or i == '。' or i == '？':\n",
    "                y.append(sentence)\n",
    "                sentence = list()\n",
    "            else:\n",
    "                sentence.append(i)\n",
    "                \n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = training_txt_to_list('/home/Danny/ai-cup-2020/datasets/stage1/SampleData_deid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2 = training_txt_to_list('/home/Danny/ai-cup-2020/datasets/stage2/train_1_update.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4, y4 = training_txt_to_list('/home/Danny/ai-cup-2020/datasets/stage4/train_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76162\n",
      "76162\n"
     ]
    }
   ],
   "source": [
    "x = x1 + x2 + x4\n",
    "y = y1 + y2 + y4\n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48743 48743\n",
      "12186 12186\n",
      "15233 15233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(valid_x), len(valid_y))\n",
    "print(len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-23 00:52:56,041 [DEBUG] kashgari - ------------------------------------------------\n",
      "2020-12-23 00:52:56,041 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2020-12-23 00:52:56,042 [DEBUG] kashgari - config_path       : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_config.json\n",
      "2020-12-23 00:52:56,042 [DEBUG] kashgari - vocab_path      : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/vocab.txt\n",
      "2020-12-23 00:52:56,043 [DEBUG] kashgari - checkpoint_path : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt\n",
      "2020-12-23 00:52:56,043 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2020-12-23 00:52:56,043 [DEBUG] kashgari - ------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import kashgari\n",
    "from kashgari.tasks.labeling import BiLSTM_CRF_Model\n",
    "from kashgari.embeddings import TransformerEmbedding\n",
    "from keras_radam import RAdam\n",
    "kashgari.config.use_cudnn_cell = True\n",
    "\n",
    "embedding_path = '/home/Danny/pretrain_model/{}'.format(model_name)\n",
    "vocab_path = os.path.join(embedding_path, 'vocab.txt')\n",
    "config_path = os.path.join(embedding_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(embedding_path, 'bert_model.ckpt')\n",
    "embedding = TransformerEmbedding(vocab_path, \n",
    "                                 config_path, \n",
    "                                 checkpoint_path,\n",
    "                                 bert_type='bert',\n",
    "                                 sequence_length='auto',\n",
    "                                 trainable=True,\n",
    "                                 task='kashgari.LABELING',\n",
    "                                )\n",
    "\n",
    "model = BiLSTM_CRF_Model(embedding)\n",
    "# model.build_model(train_x, train_y)\n",
    "# model.compile_model(optimizer=RAdam(lr=3e-5))\n",
    "# hyper = model.default_hyper_parameters()\n",
    "# print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing text vocab dict: 100%|██████████| 48743/48743 [00:00<00:00, 381058.02it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 12186/12186 [00:00<00:00, 393497.54it/s]\n",
      "2020-12-23 00:52:56,213 [DEBUG] kashgari - --- Build vocab dict finished, Total: 1742 ---\n",
      "2020-12-23 00:52:56,213 [DEBUG] kashgari - Top-10: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '：', '師', '是', '民', '眾', '醫']\n",
      "Preparing text vocab dict: 100%|██████████| 48743/48743 [00:00<00:00, 521512.89it/s]\n",
      "Preparing text vocab dict: 100%|██████████| 12186/12186 [00:00<00:00, 479045.77it/s]\n",
      "2020-12-23 00:52:56,336 [DEBUG] kashgari - --- Build vocab dict finished, Total: 28 ---\n",
      "2020-12-23 00:52:56,337 [DEBUG] kashgari - Top-10: ['[PAD]', 'O', 'I-time', 'B-time', 'I-med_exam', 'I-name', 'I-location', 'B-med_exam', 'I-money', 'B-name']\n",
      "Calculating sequence length: 100%|██████████| 48743/48743 [00:00<00:00, 1294647.47it/s]\n",
      "Calculating sequence length: 100%|██████████| 12186/12186 [00:00<00:00, 1274290.41it/s]\n",
      "2020-12-23 00:53:03,638 [DEBUG] kashgari - Calculated sequence length = 19\n",
      "2020-12-23 00:53:05,961 [DEBUG] kashgari - fit input shape: (2, 1024, 19)\n",
      "2020-12-23 00:53:05,962 [DEBUG] kashgari - fit input shape: (1024, 19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 1.6834 - accuracy: 0.9369 - val_loss: 25.0780 - val_accuracy: 0.9774\n",
      "Epoch 2/512\n",
      "47/47 [==============================] - 154s 3s/step - loss: 0.4278 - accuracy: 0.9800 - val_loss: 25.0927 - val_accuracy: 0.9819\n",
      "Epoch 3/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.3140 - accuracy: 0.9827 - val_loss: 24.9384 - val_accuracy: 0.9843\n",
      "Epoch 4/512\n",
      "47/47 [==============================] - 183s 4s/step - loss: 0.2467 - accuracy: 0.9851 - val_loss: 24.8642 - val_accuracy: 0.9866\n",
      "Epoch 5/512\n",
      "47/47 [==============================] - 186s 4s/step - loss: 0.2107 - accuracy: 0.9866 - val_loss: 24.8554 - val_accuracy: 0.9874\n",
      "Epoch 6/512\n",
      "47/47 [==============================] - 188s 4s/step - loss: 0.1863 - accuracy: 0.9880 - val_loss: 24.7136 - val_accuracy: 0.9892\n",
      "Epoch 7/512\n",
      "47/47 [==============================] - 163s 3s/step - loss: 0.1677 - accuracy: 0.9892 - val_loss: 24.7041 - val_accuracy: 0.9898\n",
      "Epoch 8/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.1505 - accuracy: 0.9900 - val_loss: 24.6331 - val_accuracy: 0.9903\n",
      "Epoch 9/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.1364 - accuracy: 0.9908 - val_loss: 24.5933 - val_accuracy: 0.9906\n",
      "Epoch 10/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.1270 - accuracy: 0.9913 - val_loss: 24.5089 - val_accuracy: 0.9909\n",
      "Epoch 11/512\n",
      "47/47 [==============================] - 186s 4s/step - loss: 0.1175 - accuracy: 0.9918 - val_loss: 24.5269 - val_accuracy: 0.9913\n",
      "Epoch 12/512\n",
      "47/47 [==============================] - 186s 4s/step - loss: 0.1104 - accuracy: 0.9922 - val_loss: 24.4444 - val_accuracy: 0.9914\n",
      "Epoch 13/512\n",
      "47/47 [==============================] - 183s 4s/step - loss: 0.1002 - accuracy: 0.9929 - val_loss: 24.4451 - val_accuracy: 0.9919\n",
      "Epoch 14/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.0941 - accuracy: 0.9933 - val_loss: 24.3995 - val_accuracy: 0.9926\n",
      "Epoch 15/512\n",
      "47/47 [==============================] - 185s 4s/step - loss: 0.0883 - accuracy: 0.9936 - val_loss: 24.3752 - val_accuracy: 0.9923\n",
      "Epoch 16/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.0809 - accuracy: 0.9941 - val_loss: 24.3668 - val_accuracy: 0.9923\n",
      "Epoch 17/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.0734 - accuracy: 0.9948 - val_loss: 24.2355 - val_accuracy: 0.9923\n",
      "Epoch 18/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.0693 - accuracy: 0.9951 - val_loss: 24.2357 - val_accuracy: 0.9922\n",
      "Epoch 19/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.0646 - accuracy: 0.9953 - val_loss: 24.2886 - val_accuracy: 0.9926\n",
      "Epoch 20/512\n",
      "47/47 [==============================] - 171s 4s/step - loss: 0.0590 - accuracy: 0.9957 - val_loss: 24.1858 - val_accuracy: 0.9929\n",
      "Epoch 21/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0531 - accuracy: 0.9963 - val_loss: 24.1110 - val_accuracy: 0.9933\n",
      "Epoch 22/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.0507 - accuracy: 0.9963 - val_loss: 24.0558 - val_accuracy: 0.9931\n",
      "Epoch 23/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0481 - accuracy: 0.9965 - val_loss: 24.0467 - val_accuracy: 0.9931\n",
      "Epoch 24/512\n",
      "47/47 [==============================] - 159s 3s/step - loss: 0.0454 - accuracy: 0.9969 - val_loss: 23.9636 - val_accuracy: 0.9932\n",
      "Epoch 25/512\n",
      "47/47 [==============================] - 119s 3s/step - loss: 0.0422 - accuracy: 0.9969 - val_loss: 24.0387 - val_accuracy: 0.9936\n",
      "Epoch 26/512\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.0389 - accuracy: 0.9973 - val_loss: 23.9625 - val_accuracy: 0.9935\n",
      "Epoch 27/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0368 - accuracy: 0.9975 - val_loss: 23.9430 - val_accuracy: 0.9933\n",
      "Epoch 28/512\n",
      "47/47 [==============================] - 173s 4s/step - loss: 0.0348 - accuracy: 0.9974 - val_loss: 23.9500 - val_accuracy: 0.9938\n",
      "Epoch 29/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0314 - accuracy: 0.9978 - val_loss: 23.9378 - val_accuracy: 0.9934\n",
      "Epoch 30/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0321 - accuracy: 0.9977 - val_loss: 23.9353 - val_accuracy: 0.9935\n",
      "Epoch 31/512\n",
      "47/47 [==============================] - 174s 4s/step - loss: 0.0304 - accuracy: 0.9977 - val_loss: 23.8601 - val_accuracy: 0.9935\n",
      "Epoch 32/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0271 - accuracy: 0.9981 - val_loss: 23.8240 - val_accuracy: 0.9939\n",
      "Epoch 33/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0264 - accuracy: 0.9982 - val_loss: 23.8343 - val_accuracy: 0.9930\n",
      "Epoch 34/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0261 - accuracy: 0.9982 - val_loss: 23.8383 - val_accuracy: 0.9940\n",
      "Epoch 35/512\n",
      "47/47 [==============================] - 111s 2s/step - loss: 0.0234 - accuracy: 0.9984 - val_loss: 23.7858 - val_accuracy: 0.9938\n",
      "Epoch 36/512\n",
      "47/47 [==============================] - 109s 2s/step - loss: 0.0245 - accuracy: 0.9982 - val_loss: 23.7648 - val_accuracy: 0.9934\n",
      "Epoch 37/512\n",
      "47/47 [==============================] - 108s 2s/step - loss: 0.0220 - accuracy: 0.9986 - val_loss: 23.7189 - val_accuracy: 0.9940\n",
      "Epoch 38/512\n",
      "47/47 [==============================] - 108s 2s/step - loss: 0.0203 - accuracy: 0.9986 - val_loss: 23.7405 - val_accuracy: 0.9937\n",
      "Epoch 39/512\n",
      "47/47 [==============================] - 107s 2s/step - loss: 0.0207 - accuracy: 0.9985 - val_loss: 23.7275 - val_accuracy: 0.9935\n",
      "Epoch 40/512\n",
      "47/47 [==============================] - 109s 2s/step - loss: 0.0210 - accuracy: 0.9984 - val_loss: 23.6928 - val_accuracy: 0.9933\n",
      "Epoch 41/512\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.0204 - accuracy: 0.9985 - val_loss: 23.7280 - val_accuracy: 0.9936\n",
      "Epoch 42/512\n",
      "47/47 [==============================] - 166s 4s/step - loss: 0.0169 - accuracy: 0.9988 - val_loss: 23.6917 - val_accuracy: 0.9927\n",
      "Epoch 43/512\n",
      "47/47 [==============================] - 167s 4s/step - loss: 0.0175 - accuracy: 0.9987 - val_loss: 23.6032 - val_accuracy: 0.9926\n",
      "Epoch 44/512\n",
      "47/47 [==============================] - 171s 4s/step - loss: 0.0165 - accuracy: 0.9989 - val_loss: 23.6113 - val_accuracy: 0.9926\n",
      "Epoch 45/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0152 - accuracy: 0.9989 - val_loss: 23.6115 - val_accuracy: 0.9920\n",
      "Epoch 46/512\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.0159 - accuracy: 0.9988 - val_loss: 23.5713 - val_accuracy: 0.9920\n",
      "Epoch 47/512\n",
      "47/47 [==============================] - 174s 4s/step - loss: 0.0148 - accuracy: 0.9989 - val_loss: 23.5724 - val_accuracy: 0.9921\n",
      "Epoch 48/512\n",
      "47/47 [==============================] - 176s 4s/step - loss: 0.0159 - accuracy: 0.9988 - val_loss: 23.5888 - val_accuracy: 0.9921\n",
      "Epoch 49/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0144 - accuracy: 0.9989 - val_loss: 23.5714 - val_accuracy: 0.9876\n",
      "Epoch 50/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0141 - accuracy: 0.9990 - val_loss: 23.5327 - val_accuracy: 0.9864\n",
      "Epoch 51/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0139 - accuracy: 0.9990 - val_loss: 23.5332 - val_accuracy: 0.9864\n",
      "Epoch 52/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0137 - accuracy: 0.9989 - val_loss: 23.5270 - val_accuracy: 0.9856\n",
      "Epoch 53/512\n",
      "47/47 [==============================] - 176s 4s/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 23.5019 - val_accuracy: 0.9859\n",
      "Epoch 54/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 23.5209 - val_accuracy: 0.9847\n",
      "Epoch 55/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0145 - accuracy: 0.9989 - val_loss: 23.4547 - val_accuracy: 0.9865\n",
      "Epoch 56/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0133 - accuracy: 0.9989 - val_loss: 23.4002 - val_accuracy: 0.9866\n",
      "Epoch 57/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 23.4178 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 23.4582 - val_accuracy: 0.9856\n",
      "Epoch 59/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0110 - accuracy: 0.9991 - val_loss: 23.3722 - val_accuracy: 0.9860\n",
      "Epoch 60/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 23.3867 - val_accuracy: 0.9856\n",
      "Epoch 61/512\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.0111 - accuracy: 0.9991 - val_loss: 23.3444 - val_accuracy: 0.9864\n",
      "Epoch 62/512\n",
      "47/47 [==============================] - 179s 4s/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 23.3452 - val_accuracy: 0.9858\n",
      "Epoch 63/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0110 - accuracy: 0.9991 - val_loss: 23.3961 - val_accuracy: 0.9859\n",
      "Epoch 64/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 23.3119 - val_accuracy: 0.9862\n",
      "Epoch 65/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0114 - accuracy: 0.9990 - val_loss: 23.2895 - val_accuracy: 0.9861\n",
      "Epoch 66/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 23.3069 - val_accuracy: 0.9862\n",
      "Epoch 67/512\n",
      "47/47 [==============================] - 155s 3s/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 23.2740 - val_accuracy: 0.9859\n",
      "Epoch 68/512\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 23.2671 - val_accuracy: 0.9855\n",
      "Epoch 69/512\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 23.2242 - val_accuracy: 0.9858\n",
      "Epoch 70/512\n",
      "47/47 [==============================] - 129s 3s/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 23.2543 - val_accuracy: 0.9861\n",
      "Epoch 71/512\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 23.2185 - val_accuracy: 0.9856\n",
      "Epoch 72/512\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 23.2104 - val_accuracy: 0.9856\n",
      "Epoch 73/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 23.1786 - val_accuracy: 0.9848\n",
      "Epoch 74/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 23.1851 - val_accuracy: 0.9833\n",
      "Epoch 75/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 23.1133 - val_accuracy: 0.8529\n",
      "Epoch 76/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 23.1647 - val_accuracy: 0.7923\n",
      "Epoch 77/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 23.1469 - val_accuracy: 0.7081\n",
      "Epoch 78/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 23.1539 - val_accuracy: 0.6607\n",
      "Epoch 79/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 23.0993 - val_accuracy: 0.6106\n",
      "Epoch 80/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 23.1043 - val_accuracy: 0.5624\n",
      "Epoch 81/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 23.0709 - val_accuracy: 0.5619\n",
      "Epoch 82/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 23.0836 - val_accuracy: 0.5015\n",
      "Epoch 83/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 23.0178 - val_accuracy: 0.5066\n",
      "Epoch 84/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 23.0423 - val_accuracy: 0.5051\n",
      "Epoch 85/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 23.0426 - val_accuracy: 0.4444\n",
      "Epoch 86/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 23.0056 - val_accuracy: 0.4444\n",
      "Epoch 87/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 23.0028 - val_accuracy: 0.3884\n",
      "Epoch 88/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 22.9589 - val_accuracy: 0.3902\n",
      "Epoch 89/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 22.9326 - val_accuracy: 0.3908\n",
      "Epoch 90/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 22.9430 - val_accuracy: 0.3237\n",
      "Epoch 91/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 22.9074 - val_accuracy: 0.3220\n",
      "Epoch 92/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 22.9323 - val_accuracy: 0.3210\n",
      "Epoch 93/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 22.8304 - val_accuracy: 0.3211\n",
      "Epoch 94/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 22.8711 - val_accuracy: 0.2563\n",
      "Epoch 95/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 22.8083 - val_accuracy: 0.2592\n",
      "Epoch 96/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 22.8219 - val_accuracy: 0.2571\n",
      "Epoch 97/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 22.8181 - val_accuracy: 0.2553\n",
      "Epoch 98/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 22.8204 - val_accuracy: 0.2530\n",
      "Epoch 99/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 22.7156 - val_accuracy: 0.1773\n",
      "Epoch 100/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 22.7615 - val_accuracy: 0.1756\n",
      "Epoch 101/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 22.7365 - val_accuracy: 0.1748\n",
      "Epoch 102/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 22.7267 - val_accuracy: 0.1738\n",
      "Epoch 103/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 22.7216 - val_accuracy: 0.1750\n",
      "Epoch 104/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 22.6650 - val_accuracy: 0.1732\n",
      "Epoch 105/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 22.6488 - val_accuracy: 0.1714\n",
      "Epoch 106/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 22.6784 - val_accuracy: 0.1715\n",
      "Epoch 107/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 22.6199 - val_accuracy: 0.1708\n",
      "Epoch 108/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 22.5869 - val_accuracy: 0.1725\n",
      "Epoch 109/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 22.5963 - val_accuracy: 0.1703\n",
      "Epoch 110/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 22.5676 - val_accuracy: 0.1711\n",
      "Epoch 111/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 22.6093 - val_accuracy: 0.1583\n",
      "Epoch 112/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 22.5371 - val_accuracy: 0.1580\n",
      "Epoch 113/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 22.5024 - val_accuracy: 0.1566\n",
      "Epoch 114/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 22.5100 - val_accuracy: 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 22.4655 - val_accuracy: 0.1577\n",
      "Epoch 116/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 22.4970 - val_accuracy: 0.1563\n",
      "Epoch 117/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 22.4735 - val_accuracy: 0.0683\n",
      "Epoch 118/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 22.4369 - val_accuracy: 0.0671\n",
      "Epoch 119/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 22.4527 - val_accuracy: 0.0675\n",
      "Epoch 120/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 22.3800 - val_accuracy: 0.0682\n",
      "Epoch 121/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 22.3686 - val_accuracy: 0.0669\n",
      "Epoch 122/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 22.3606 - val_accuracy: 0.0646\n",
      "Epoch 123/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 22.3487 - val_accuracy: 0.0655\n",
      "Epoch 124/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 22.3398 - val_accuracy: 0.0511\n",
      "Epoch 125/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 22.2627 - val_accuracy: 0.0515\n",
      "Epoch 126/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 22.2764 - val_accuracy: 0.0509\n",
      "Epoch 127/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 22.2189 - val_accuracy: 0.0511\n",
      "Epoch 128/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 22.2369 - val_accuracy: 0.0519\n",
      "Epoch 129/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 22.2410 - val_accuracy: 0.0425\n",
      "Epoch 130/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 22.1886 - val_accuracy: 0.0433\n",
      "Epoch 131/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 22.1986 - val_accuracy: 0.0430\n",
      "Epoch 132/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 22.1427 - val_accuracy: 0.0426\n",
      "Epoch 133/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 22.1128 - val_accuracy: 0.0438\n",
      "Epoch 134/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 22.1163 - val_accuracy: 0.0432\n",
      "Epoch 135/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 22.0746 - val_accuracy: 0.0442\n",
      "Epoch 136/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 22.0566 - val_accuracy: 0.0434\n",
      "Epoch 137/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 22.0186 - val_accuracy: 0.0433\n",
      "Epoch 138/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 22.0342 - val_accuracy: 0.0344\n",
      "Epoch 139/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 22.0099 - val_accuracy: 0.0345\n",
      "Epoch 140/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 21.9609 - val_accuracy: 0.0373\n",
      "Epoch 141/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 21.9480 - val_accuracy: 0.0377\n",
      "Epoch 142/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 21.8982 - val_accuracy: 0.0333\n",
      "Epoch 143/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 21.9212 - val_accuracy: 0.0339\n",
      "Epoch 144/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 21.8575 - val_accuracy: 0.0338\n",
      "Epoch 145/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 21.8703 - val_accuracy: 0.0350\n",
      "Epoch 146/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 21.8440 - val_accuracy: 0.0339\n",
      "Epoch 147/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 21.7940 - val_accuracy: 0.0333\n",
      "Epoch 148/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 21.7931 - val_accuracy: 0.0313\n",
      "Epoch 149/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 21.7686 - val_accuracy: 0.0318\n",
      "Epoch 150/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 21.7070 - val_accuracy: 0.0314\n",
      "Epoch 151/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 21.7037 - val_accuracy: 0.0314\n",
      "Epoch 152/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 21.6910 - val_accuracy: 0.0324\n",
      "Epoch 153/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 21.6510 - val_accuracy: 0.0327\n",
      "Epoch 154/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 21.6738 - val_accuracy: 0.0297\n",
      "Epoch 155/512\n",
      "47/47 [==============================] - 118s 3s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 21.6207 - val_accuracy: 0.0322\n",
      "Epoch 156/512\n",
      "47/47 [==============================] - 106s 2s/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 21.5428 - val_accuracy: 0.0300\n",
      "Epoch 157/512\n",
      "47/47 [==============================] - 103s 2s/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 21.5589 - val_accuracy: 0.0305\n",
      "Epoch 158/512\n",
      "47/47 [==============================] - 109s 2s/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 21.5674 - val_accuracy: 0.0295\n",
      "Epoch 159/512\n",
      "47/47 [==============================] - 120s 3s/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 21.5091 - val_accuracy: 0.0304\n",
      "Epoch 160/512\n",
      "47/47 [==============================] - 120s 3s/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 21.5033 - val_accuracy: 0.0295\n",
      "Epoch 161/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 21.4767 - val_accuracy: 0.0296\n",
      "Epoch 162/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 21.4172 - val_accuracy: 0.0309\n",
      "Epoch 163/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 21.3636 - val_accuracy: 0.0312\n",
      "Epoch 164/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 21.3702 - val_accuracy: 0.0302\n",
      "Epoch 165/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 21.4022 - val_accuracy: 0.0300\n",
      "Epoch 166/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 21.3535 - val_accuracy: 0.0293\n",
      "Epoch 167/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 21.3685 - val_accuracy: 0.0303\n",
      "Epoch 168/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 21.2779 - val_accuracy: 0.0307\n",
      "Epoch 169/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 21.2857 - val_accuracy: 0.0281\n",
      "Epoch 170/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 21.2467 - val_accuracy: 0.0280\n",
      "Epoch 171/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 21.2237 - val_accuracy: 0.0289\n",
      "Epoch 172/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 21.1955 - val_accuracy: 0.0304\n",
      "Epoch 173/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 21.1753 - val_accuracy: 0.0315\n",
      "Epoch 174/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 21.1608 - val_accuracy: 0.0307\n",
      "Epoch 175/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 21.0702 - val_accuracy: 0.0313\n",
      "Epoch 176/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 21.0787 - val_accuracy: 0.0291\n",
      "Epoch 177/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 21.0758 - val_accuracy: 0.0313\n",
      "Epoch 178/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 21.0269 - val_accuracy: 0.0289\n",
      "Epoch 179/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 20.9658 - val_accuracy: 0.0287\n",
      "Epoch 180/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 20.9373 - val_accuracy: 0.0290\n",
      "Epoch 181/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 20.8740 - val_accuracy: 0.0295\n",
      "Epoch 182/512\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 20.8835 - val_accuracy: 0.0286\n",
      "Epoch 183/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 20.8836 - val_accuracy: 0.0282\n",
      "Epoch 184/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 20.8520 - val_accuracy: 0.0291\n",
      "Epoch 185/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 20.8186 - val_accuracy: 0.0285\n",
      "Epoch 186/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 20.8128 - val_accuracy: 0.0288\n",
      "Epoch 187/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 20.7857 - val_accuracy: 0.0291\n",
      "Epoch 188/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 20.7620 - val_accuracy: 0.0298\n",
      "Epoch 189/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 20.7400 - val_accuracy: 0.0293\n",
      "Epoch 190/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 20.7072 - val_accuracy: 0.0285\n",
      "Epoch 191/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 20.6815 - val_accuracy: 0.0280\n",
      "Epoch 192/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 20.6564 - val_accuracy: 0.0289\n",
      "Epoch 193/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 20.6161 - val_accuracy: 0.0280\n",
      "Epoch 194/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 20.5965 - val_accuracy: 0.0285\n",
      "Epoch 195/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 20.5891 - val_accuracy: 0.0275\n",
      "Epoch 196/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 20.5452 - val_accuracy: 0.0269\n",
      "Epoch 197/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 20.4782 - val_accuracy: 0.0261\n",
      "Epoch 198/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 20.4644 - val_accuracy: 0.0253\n",
      "Epoch 199/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 20.4751 - val_accuracy: 0.0252\n",
      "Epoch 200/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 20.4623 - val_accuracy: 0.0255\n",
      "Epoch 201/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 20.3916 - val_accuracy: 0.0251\n",
      "Epoch 202/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 20.4280 - val_accuracy: 0.0262\n",
      "Epoch 203/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 20.4180 - val_accuracy: 0.0256\n",
      "Epoch 204/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 20.4092 - val_accuracy: 0.0257\n",
      "Epoch 205/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 20.3576 - val_accuracy: 0.0260\n",
      "Epoch 206/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 20.3536 - val_accuracy: 0.0265\n",
      "Epoch 207/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 20.2989 - val_accuracy: 0.0258\n",
      "Epoch 208/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 20.3001 - val_accuracy: 0.0258\n",
      "Epoch 209/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 20.2224 - val_accuracy: 0.0258\n",
      "Epoch 210/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 20.2705 - val_accuracy: 0.0261\n",
      "Epoch 211/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 20.1976 - val_accuracy: 0.0259\n",
      "Epoch 212/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 20.1809 - val_accuracy: 0.0250\n",
      "Epoch 213/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 20.1749 - val_accuracy: 0.0250\n",
      "Epoch 214/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 20.1312 - val_accuracy: 0.0248\n",
      "Epoch 215/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 20.1454 - val_accuracy: 0.0254\n",
      "Epoch 216/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 20.1020 - val_accuracy: 0.0253\n",
      "Epoch 217/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 20.0732 - val_accuracy: 0.0238\n",
      "Epoch 218/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 20.0179 - val_accuracy: 0.0254\n",
      "Epoch 219/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 20.0125 - val_accuracy: 0.0253\n",
      "Epoch 220/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 20.0078 - val_accuracy: 0.0248\n",
      "Epoch 221/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 19.9639 - val_accuracy: 0.0254\n",
      "Epoch 222/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 19.9186 - val_accuracy: 0.0248\n",
      "Epoch 223/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 19.9449 - val_accuracy: 0.0244\n",
      "Epoch 224/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 19.9347 - val_accuracy: 0.0248\n",
      "Epoch 225/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 19.8741 - val_accuracy: 0.0244\n",
      "Epoch 226/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 19.8276 - val_accuracy: 0.0239\n",
      "Epoch 227/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 125s 3s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 19.8714 - val_accuracy: 0.0244\n",
      "Epoch 228/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 19.8692 - val_accuracy: 0.0250\n",
      "Epoch 229/512\n",
      "47/47 [==============================] - 124s 3s/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 19.8021 - val_accuracy: 0.0244\n",
      "Epoch 230/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 19.8247 - val_accuracy: 0.0252\n",
      "Epoch 231/512\n",
      "47/47 [==============================] - 123s 3s/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 19.7714 - val_accuracy: 0.0250\n",
      "Epoch 232/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 19.7753 - val_accuracy: 0.0248\n",
      "Epoch 233/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 19.7641 - val_accuracy: 0.0245\n",
      "Epoch 234/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 19.7242 - val_accuracy: 0.0251\n",
      "Epoch 235/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 19.6751 - val_accuracy: 0.0248\n",
      "Epoch 236/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 19.6428 - val_accuracy: 0.0248\n",
      "Epoch 237/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 19.6401 - val_accuracy: 0.0241\n",
      "Epoch 238/512\n",
      "47/47 [==============================] - 132s 3s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 19.6010 - val_accuracy: 0.0247\n",
      "Epoch 239/512\n",
      "47/47 [==============================] - 138s 3s/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 19.5962 - val_accuracy: 0.0249\n",
      "Epoch 240/512\n",
      "47/47 [==============================] - 128s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 19.5403 - val_accuracy: 0.0232\n",
      "Epoch 241/512\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 19.5569 - val_accuracy: 0.0237\n",
      "Epoch 242/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 19.5022 - val_accuracy: 0.0221\n",
      "Epoch 243/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 19.4901 - val_accuracy: 0.0228\n",
      "Epoch 244/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 19.4194 - val_accuracy: 0.0216\n",
      "Epoch 245/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 19.4162 - val_accuracy: 0.0221\n",
      "Epoch 246/512\n",
      "47/47 [==============================] - 126s 3s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.4115 - val_accuracy: 0.0221\n",
      "Epoch 247/512\n",
      "47/47 [==============================] - 113s 2s/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 19.4054 - val_accuracy: 0.0217\n",
      "Epoch 248/512\n",
      "47/47 [==============================] - 107s 2s/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 19.3787 - val_accuracy: 0.0220\n",
      "Epoch 249/512\n",
      "47/47 [==============================] - 132s 3s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.3143 - val_accuracy: 0.0219\n",
      "Epoch 250/512\n",
      "47/47 [==============================] - 160s 3s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 19.3445 - val_accuracy: 0.0218\n",
      "Epoch 251/512\n",
      "47/47 [==============================] - 167s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.3088 - val_accuracy: 0.0220\n",
      "Epoch 252/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 19.2457 - val_accuracy: 0.0210\n",
      "Epoch 253/512\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 19.2629 - val_accuracy: 0.0213\n",
      "Epoch 254/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 19.2598 - val_accuracy: 0.0217\n",
      "Epoch 255/512\n",
      "47/47 [==============================] - 166s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.2376 - val_accuracy: 0.0202\n",
      "Epoch 256/512\n",
      "47/47 [==============================] - 178s 4s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 19.1923 - val_accuracy: 0.0193\n",
      "Epoch 257/512\n",
      "47/47 [==============================] - 181s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.1664 - val_accuracy: 0.0189\n",
      "Epoch 258/512\n",
      "47/47 [==============================] - 182s 4s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 19.1982 - val_accuracy: 0.0180\n",
      "Epoch 259/512\n",
      "47/47 [==============================] - 188s 4s/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 19.1527 - val_accuracy: 0.0193\n",
      "Epoch 260/512\n",
      "47/47 [==============================] - 188s 4s/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 19.1688 - val_accuracy: 0.0184\n",
      "Epoch 261/512\n",
      "47/47 [==============================] - 190s 4s/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 19.1162 - val_accuracy: 0.0187\n",
      "Epoch 262/512\n",
      "47/47 [==============================] - 190s 4s/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 19.1165 - val_accuracy: 0.0190\n",
      "Epoch 263/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 19.1090 - val_accuracy: 0.0188\n",
      "Epoch 264/512\n",
      "47/47 [==============================] - 184s 4s/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 19.0750 - val_accuracy: 0.0181\n",
      "Epoch 265/512\n",
      "47/47 [==============================] - 185s 4s/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 19.0708 - val_accuracy: 0.0191\n",
      "Epoch 266/512\n",
      "47/47 [==============================] - 186s 4s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 19.0855 - val_accuracy: 0.0189\n",
      "Epoch 267/512\n",
      "47/47 [==============================] - 183s 4s/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 19.0413 - val_accuracy: 0.0183\n",
      "Epoch 268/512\n",
      "47/47 [==============================] - 187s 4s/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 19.0385 - val_accuracy: 0.0189\n",
      "Epoch 269/512\n",
      "47/47 [==============================] - 177s 4s/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 19.0292 - val_accuracy: 0.0185\n",
      "Epoch 270/512\n",
      "47/47 [==============================] - 180s 4s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 19.0310 - val_accuracy: 0.0186\n",
      "Epoch 271/512\n",
      "47/47 [==============================] - 157s 3s/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 19.0263 - val_accuracy: 0.0179\n",
      "Epoch 272/512\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 18.9712 - val_accuracy: 0.0187\n",
      "Epoch 273/512\n",
      "47/47 [==============================] - 138s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 18.9749 - val_accuracy: 0.0178\n",
      "Epoch 274/512\n",
      "47/47 [==============================] - 119s 3s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 18.8652 - val_accuracy: 0.0186\n",
      "Epoch 275/512\n",
      "47/47 [==============================] - 108s 2s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 18.9243 - val_accuracy: 0.0177\n",
      "Epoch 276/512\n",
      "47/47 [==============================] - 125s 3s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 18.8891 - val_accuracy: 0.0180\n",
      "Epoch 277/512\n",
      "47/47 [==============================] - 155s 3s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 18.8730 - val_accuracy: 0.0177\n",
      "Epoch 278/512\n",
      "47/47 [==============================] - 166s 4s/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 18.8462 - val_accuracy: 0.0175\n",
      "Epoch 279/512\n",
      "47/47 [==============================] - 169s 4s/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 18.8396 - val_accuracy: 0.0175\n",
      "Epoch 280/512\n",
      "47/47 [==============================] - 165s 4s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 18.8171 - val_accuracy: 0.0165\n",
      "Epoch 281/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 18.8304 - val_accuracy: 0.0168\n",
      "Epoch 282/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 18.8121 - val_accuracy: 0.0159\n",
      "Epoch 283/512\n",
      "47/47 [==============================] - 174s 4s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 18.7773 - val_accuracy: 0.0163\n",
      "Epoch 284/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 18.7478 - val_accuracy: 0.0166\n",
      "Epoch 285/512\n",
      "47/47 [==============================] - 170s 4s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 18.7363 - val_accuracy: 0.0162\n",
      "Epoch 286/512\n",
      "47/47 [==============================] - 166s 4s/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 18.7092 - val_accuracy: 0.0157\n",
      "Epoch 287/512\n",
      "47/47 [==============================] - 173s 4s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 18.6761 - val_accuracy: 0.0166\n",
      "Epoch 288/512\n",
      "47/47 [==============================] - 171s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 18.7051 - val_accuracy: 0.0158\n",
      "Epoch 289/512\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 18.6331 - val_accuracy: 0.0161\n",
      "Epoch 290/512\n",
      "47/47 [==============================] - 172s 4s/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 18.6862 - val_accuracy: 0.0154\n",
      "Epoch 291/512\n",
      "47/47 [==============================] - 176s 4s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 18.6726 - val_accuracy: 0.0159\n",
      "Epoch 292/512\n",
      "47/47 [==============================] - 151s 3s/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 18.6171 - val_accuracy: 0.0153\n",
      "Epoch 293/512\n",
      "47/47 [==============================] - 141s 3s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 18.5956 - val_accuracy: 0.0156\n",
      "Epoch 294/512\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 18.6447 - val_accuracy: 0.0159\n",
      "Epoch 295/512\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 18.6355 - val_accuracy: 0.0157\n",
      "Epoch 296/512\n",
      "47/47 [==============================] - 135s 3s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 18.5869 - val_accuracy: 0.0153\n",
      "Epoch 297/512\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 18.5704 - val_accuracy: 0.0152\n",
      "Epoch 298/512\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 18.5880 - val_accuracy: 0.0147\n",
      "Epoch 299/512\n",
      "47/47 [==============================] - 128s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 18.5877 - val_accuracy: 0.0148\n",
      "Epoch 300/512\n",
      "47/47 [==============================] - 130s 3s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 18.5286 - val_accuracy: 0.0144\n",
      "Epoch 301/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 18.5316 - val_accuracy: 0.0150\n",
      "Epoch 302/512\n",
      "47/47 [==============================] - 127s 3s/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 18.5343 - val_accuracy: 0.0146\n",
      "Epoch 303/512\n",
      " 5/47 [==>...........................] - ETA: 1:16 - loss: 0.0044 - accuracy: 0.9992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/kashgari/tasks/labeling/abc_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_validate, y_validate, batch_size, epochs, callbacks, fit_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                                   fit_kwargs=fit_kwargs)\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     def fit_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/kashgari/tasks/labeling/abc_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, train_sample_gen, valid_sample_gen, batch_size, epochs, callbacks, fit_kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                                  **fit_kwargs)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     def predict(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_x,\n",
    "                    train_y,\n",
    "                    valid_x,\n",
    "                    valid_y,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/{}_epoch_{}_batch_{}'.format(model_name, epochs, batch_size)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Danny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: The 'load_model' function is deprecated, use 'XX_Model.load_model' instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2020-12-23 13:03:59,978 [DEBUG] kashgari - ------------------------------------------------\n",
      "2020-12-23 13:03:59,979 [DEBUG] kashgari - Loaded transformer model's vocab\n",
      "2020-12-23 13:03:59,979 [DEBUG] kashgari - config_path       : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_config.json\n",
      "2020-12-23 13:03:59,979 [DEBUG] kashgari - vocab_path      : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/vocab.txt\n",
      "2020-12-23 13:03:59,980 [DEBUG] kashgari - checkpoint_path : /home/Danny/pretrain_model/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt\n",
      "2020-12-23 13:03:59,980 [DEBUG] kashgari - Top 50 words    : ['[PAD]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]']\n",
      "2020-12-23 13:03:59,981 [DEBUG] kashgari - ------------------------------------------------\n",
      "2020-12-23 13:04:13,726 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 65\n",
      "2020-12-23 13:04:13,832 [DEBUG] kashgari - predict seq_length: None, input: (2, 15233, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/477 [==============================] - 115s 241ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-23 13:06:17,000 [DEBUG] kashgari - predict output: (15233, 65)\n",
      "2020-12-23 13:06:17,001 [DEBUG] kashgari - predict output argmax: [[0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      med_exam     0.8219    0.8955    0.8571       134\n",
      "          time     0.8431    0.8383    0.8407       878\n",
      "    profession     1.0000    0.4118    0.5833        17\n",
      "      location     0.9341    0.8333    0.8808       102\n",
      "         money     0.9487    0.8605    0.9024        43\n",
      "        family     0.8571    0.5455    0.6667        11\n",
      "          name     0.9630    0.8864    0.9231        88\n",
      "       contact     0.8571    0.6667    0.7500        18\n",
      "     education     1.0000    0.5000    0.6667         2\n",
      "            ID     1.0000    0.4444    0.6154         9\n",
      "        others     0.0000    0.0000    0.0000         1\n",
      "  organization     1.0000    1.0000    1.0000         2\n",
      "clinical_event     0.0000    0.0000    0.0000         1\n",
      "\n",
      "     micro avg     0.8601    0.8331    0.8464      1306\n",
      "     macro avg     0.8622    0.8331    0.8442      1306\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'med_exam': {'precision': 0.821917808219178,\n",
       "   'recall': 0.8955223880597015,\n",
       "   'f1-score': 0.8571428571428571,\n",
       "   'support': 134},\n",
       "  'time': {'precision': 0.843069873997709,\n",
       "   'recall': 0.8382687927107062,\n",
       "   'f1-score': 0.8406624785836665,\n",
       "   'support': 878},\n",
       "  'profession': {'precision': 1.0,\n",
       "   'recall': 0.4117647058823529,\n",
       "   'f1-score': 0.5833333333333334,\n",
       "   'support': 17},\n",
       "  'location': {'precision': 0.9340659340659341,\n",
       "   'recall': 0.8333333333333334,\n",
       "   'f1-score': 0.8808290155440415,\n",
       "   'support': 102},\n",
       "  'money': {'precision': 0.9487179487179487,\n",
       "   'recall': 0.8604651162790697,\n",
       "   'f1-score': 0.9024390243902439,\n",
       "   'support': 43},\n",
       "  'family': {'precision': 0.8571428571428571,\n",
       "   'recall': 0.5454545454545454,\n",
       "   'f1-score': 0.6666666666666665,\n",
       "   'support': 11},\n",
       "  'name': {'precision': 0.9629629629629629,\n",
       "   'recall': 0.8863636363636364,\n",
       "   'f1-score': 0.923076923076923,\n",
       "   'support': 88},\n",
       "  'contact': {'precision': 0.8571428571428571,\n",
       "   'recall': 0.6666666666666666,\n",
       "   'f1-score': 0.75,\n",
       "   'support': 18},\n",
       "  'education': {'precision': 1.0,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.6666666666666666,\n",
       "   'support': 2},\n",
       "  'ID': {'precision': 1.0,\n",
       "   'recall': 0.4444444444444444,\n",
       "   'f1-score': 0.6153846153846153,\n",
       "   'support': 9},\n",
       "  'others': {'precision': 0, 'recall': 0.0, 'f1-score': 0, 'support': 1},\n",
       "  'organization': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 2},\n",
       "  'clinical_event': {'precision': 0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0,\n",
       "   'support': 1}},\n",
       " 'precision': 0.86218975217369,\n",
       " 'recall': 0.8330781010719756,\n",
       " 'f1-score': 0.8441506897323421,\n",
       " 'support': 1306}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kashgari.utils import load_model\n",
    "model_path = 'model/{}_epoch_{}_batch_{}'.format(model_name, epochs, batch_size)\n",
    "model = load_model(model_path)\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f86be3741bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要儲存article_id, 轉成dataframe\n",
    "def predicting_txt_to_dataframe(path):    \n",
    "    with open(path, 'r') as f:\n",
    "        txt = str(f.read())\n",
    "        txt_list = txt.split('\\n')\n",
    "    row_list = list()\n",
    "    tmp_list = list()\n",
    "    for row in txt_list:\n",
    "        if row == '--------------------':\n",
    "            tmp_list[0] = tmp_list[0].replace('article_id:', '')\n",
    "            tmp_list[0] = int(tmp_list[0])\n",
    "            row_list.append(tmp_list)\n",
    "            tmp_list = list()\n",
    "            continue\n",
    "        if len(row) > 0:\n",
    "            tmp_list.append(row)\n",
    "    df = pd.DataFrame(row_list, columns=['article_id','text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NER(text):\n",
    "    x_list = list()    \n",
    "    text_list = re.split('\\uff0c|\\u3002|\\uff1f', text)\n",
    "    for article in text_list:\n",
    "        x_list.append([i for i in article])\n",
    "    y_list_list = model.predict(x_list)\n",
    "    y_list = list()\n",
    "    for sentence in y_list_list:\n",
    "        for word in sentence:\n",
    "            y_list.append(word)\n",
    "        y_list.append('O') # append(，。？)\n",
    "    y_list = y_list[:-1]\n",
    "    return y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_NER(article_id, text, y_list):\n",
    "    output_str = str()\n",
    "    flag = False\n",
    "    for i, j in enumerate(y_list):\n",
    "        if j != 'O':\n",
    "            if j[0] == 'B':\n",
    "                start_position = i\n",
    "                entity_type = j.split('-')[-1]\n",
    "                flag = True\n",
    "        elif j == 'O' and flag == True:\n",
    "            end_position = i\n",
    "            flag = False\n",
    "            entity_text = text[start_position: end_position]\n",
    "            entity = '{}\\t{}\\t{}\\t{}\\t{}\\n'.format(article_id, start_position, end_position, entity_text, entity_type)  \n",
    "            output_str += entity\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predicting_txt_to_dataframe('/home/Danny/ai-cup-2020/datasets/stage5/test.txt')\n",
    "output_str = \"article_id\\tstart_position\\tend_position\\tentity_text\\tentity_type\\n\"\n",
    "\n",
    "for article_id, text in zip(df['article_id'], df['text']):\n",
    "    x_list = [word for word in text]\n",
    "    y_list = predict_NER(text)\n",
    "    output_str += output_NER(article_id, text, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output/{}_epoch_{}_batch_{}.tsv'.format(model_name, epochs, batch_size)\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_path, sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
